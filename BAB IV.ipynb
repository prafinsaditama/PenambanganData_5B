{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas IV\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "Algoritma Naive Bayes merupakan sebuah metoda klasifikasi menggunakan metode probabilitas dan statistik yg dikemukakan oleh ilmuwan Inggris Thomas Bayes. Algoritma Naive Bayes memprediksi peluang di masa depan berdasarkan pengalaman di masa sebelumnya sehingga dikenal sebagai Teorema Bayes. Ciri utama dr Naïve Bayes Classifier ini adalah asumsi yg sangat kuat (naïf) akan independensi dari masing-masing kondisi / kejadian.\n",
    "\n",
    "Naive Bayes Classifier bekerja sangat baik dibanding dengan model classifier lainnya. Hal ini dibuktikan pada jurnal Xhemali, Daniela, Chris J. Hinde, and Roger G. Stone. “Naive Bayes vs. decision trees vs. neural networks in the classification of training web pages.” (2009), mengatakan bahwa “Naïve Bayes Classifier memiliki tingkat akurasi yg lebih baik dibanding model classifier lainnya”.\n",
    "\n",
    "Keuntungan penggunan adalah bahwa metoda ini hanya membutuhkan jumlah data pelatihan (training data) yang kecil untuk menentukan estimasi parameter yg diperlukan dalam proses pengklasifikasian. Karena yg diasumsikan sebagai variabel independent, maka hanya varians dari suatu variabel dalam sebuah kelas yang dibutuhkan untuk menentukan klasifikasi, bukan keseluruhan dari matriks kovarians.\n",
    "\n",
    "Tahapan dari proses algoritma Naive Bayes adalah:\n",
    "\n",
    "1. Menghitung jumlah kelas / label.\n",
    "2. Menghitung Jumlah Kasus Per Kelas\n",
    "3. Kalikan Semua Variable Kelas\n",
    "4. Bandingkan Hasil Per Kelas\n",
    " \n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-table.jpg)\n",
    "\n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-1-1.jpg)\n",
    "\n",
    "Keterangan :\n",
    "+ x : Data dengan class yang belum diketahui\n",
    "+ c : Hipotesis data merupakan suatu class spesifik\n",
    "+ P(c|x) : Probabilitas hipotesis berdasar kondisi (posteriori probability)\n",
    "+ P(c) : Probabilitas hipotesis (prior probability)\n",
    "+ P(x|c) : Probabilitas berdasarkan kondisi pada hipotesis\n",
    "+ P(x) : Probabilitas c\n",
    "\n",
    "---\n",
    "\n",
    "Rumus diatas menjelaskan bahwa peluang masuknya sampel karakteristik tertentu dalam kelas C (Posterior) adalah peluang munculnya kelas C (sebelum masuknya sampel tersebut, seringkali disebut prior), dikali dengan peluang kemunculan karakteristik karakteristik sampel pada kelas C (disebut juga likelihood), dibagi dengan peluang kemunculan karakteristik  sampel secara global ( disebut juga evidence). Karena itu, rumus diatas dapat pula ditulis sebagai berikut :\n",
    "\n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-3.jpg)\n",
    "\n",
    "Nilai Evidence selalu tetap untuk setiap kelas pada satu sampel. Nilai dari posterior tersebut nantinya akan dibandingkan dengan nilai nilai posterior kelas lainnya untuk menentukan ke kelas apa suatu sampel akan diklasifikasikan. Penjabaran lebih lanjut rumus Bayes tersebut dilakukan dengan menjabarkan (c|x1,…,xn) menggunakan aturan perkalian sebagai berikut :\n",
    "\n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-4.jpg)\n",
    " \n",
    "\n",
    "Dapat dilihat bahwa hasil penjabaran tersebut menyebabkan semakin banyak dan semakin kompleksnya faktor faktor syarat yang mempengaruhi nilai probabilitas, yang hampir mustahil untuk dianalisa satu persatu. Akibatnya, perhitungan tersebut menjadi sulit untuk dilakukan. Disinilah digunakan asumsi independensi yang sangat tinggi (naif), bahwa masing masing petunjuk saling bebas (independen) satu sama lain. Dengan asumsi tersebut, maka berlaku suatu kesamaan sebagai berikut:\n",
    "\n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-5.jpg) \n",
    "\n",
    "Persamaan diatas merupakan model dari Teorema Naive Bayes yang selanjutnya akan digunakan dalam proses klasifikasi. Untuk klasifikasi dengan data kontinyu digunakan rumus Densitas Gauss :\n",
    "\n",
    "![](https://informatikalogi.com/wp-content/uploads/2017/04/distribusi-normal-gauss.jpg)\n",
    "\n",
    "Keterangan :\n",
    "+ P : Peluang\n",
    "+ Xi : Atribut ke i\n",
    "+ xi : Nilai atribut ke i\n",
    "+ Y : Kelas yang dicari\n",
    "+ yj : Sub kelas Y yang dicari\n",
    "+ u : Mean, menyatakan rata rata dari seluruh atribut\n",
    "+ o : Deviasi standar, menyatakan varian dari seluruh atribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi:  0.8833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        39\n",
      "  versicolor       0.75      0.97      0.84        39\n",
      "   virginica       0.97      0.69      0.81        42\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.90      0.89      0.88       120\n",
      "weighted avg       0.91      0.88      0.88       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Contoh eksekusi\n",
    "\n",
    "from sklearn import datasets, model_selection\n",
    "from pandas import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = [list(s)+[iris.target_names[iris.target[i]]] for i,s in enumerate(iris.data)]\n",
    "dataset = DataFrame(data, columns=iris.feature_names+['class'])\n",
    "\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "        model_selection.train_test_split(X, Y, \\\n",
    "        train_size=0.2, random_state=2)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)\n",
    "p = classifier.predict(X_validation)\n",
    "\n",
    "print(\"Akurasi: \", accuracy_score(Y_validation, p))\n",
    "print(classification_report(Y_validation, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
